{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import binarize, LabelEncoder, MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import BaggingClassifier, AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from mlxtend.classifier import StackingClassifier"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df = pd.read_csv(\"survey.csv\")\n",
    "print(df.shape)\n",
    "print(df.info)"
   ],
   "id": "cc75e8b8c73e959a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(df.describe())",
   "id": "8e43657026fea8cd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(df.describe(include='all'))",
   "id": "2095f673ac64f668",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#checking bad data\n",
    "column = df.shape[0]\n",
    "total = df.isnull().sum()/column\n",
    "print(total)"
   ],
   "id": "6e9c69c8ffd4cffb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df.drop(['comments'], axis= 1, inplace=True)\n",
    "df.drop(['state'], axis= 1, inplace=True)\n",
    "df.drop(['Timestamp'], axis= 1, inplace=True)\n",
    "df.isnull().sum().max() #just checking that there's no missing data missing...\n",
    "\n",
    "df.head(5)"
   ],
   "id": "82df3e9f03a522de",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "defaultInt = 0\n",
    "defaultString = 'NaN'\n",
    "defaultFloat = 0.0\n",
    "# Create lists by data tpe\n",
    "intFeatures = ['Age']\n",
    "floatFeatures = []\n",
    "stringFeatures = []\n",
    "# Clean the NaN's\n",
    "for feature in df:\n",
    "    if feature in intFeatures:\n",
    "        df[feature] = df[feature].fillna(defaultInt)\n",
    "    elif feature in stringFeatures:\n",
    "        df[feature] = df[feature].fillna(defaultString)\n",
    "    elif feature in floatFeatures:\n",
    "        df[feature] = df[feature].fillna(defaultFloat)\n",
    "    else:\n",
    "        print('Error: Feature %s not identified.' % feature)\n",
    "print(df)"
   ],
   "id": "a1614ed231890a91",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "gender = df['Gender'].unique()\n",
    "print(gender)\n",
    "#Get rid of bullshit\n",
    "mistakes = ['maile', 'Make', 'Mal', 'msle', 'Mail', 'Malr', 'M', 'm', 'Man']\n",
    "for mistake in mistakes:\n",
    "    df['Gender'] = df['Gender'].replace(mistake, 'Male')\n",
    "    \n",
    "mistakes_f = ['female', 'f', 'F', 'Woman', 'woman', 'Femake','Female ', 'femail']\n",
    "for mistake_f in mistakes_f:\n",
    "    df['Gender'] = df['Gender'].replace(mistake_f, 'Female')\n",
    "    \n",
    "mis = ['Trans-female', 'non-binary', 'Trans woman', 'Female (Trans)', 'Neuter']\n",
    "for mi in mis:\n",
    "    df['Gender'] = df['Gender'].replace(mi, 'Others')\n",
    "list = ['Male', 'Female', 'Others']\n",
    "stk_list = ['A little about you', 'p', 'Male-ish', 'maile', 'Trans-female', 'Cis-female', 'something kinda male?', 'Cis Male', \n",
    "            'Mal', 'Make', 'Nah', 'Femake', 'non-binary', 'fluid','queer/she/they', 'All', 'Enby', 'Genderqueer', 'Guy (-ish) ^_^', 'Male (CIS)', 'male leaning androgynous', 'Androgyne', 'Agender','Cis Female', 'cis-female/femme', 'msle', \n",
    "            'queer','Female (trans)', 'Female (cis)','Mail', 'cis male', 'Malr', 'femail', 'Cis Man', 'ostensibly male, unsure what that really means']\n",
    "df = df[df['Gender'].isin(list)]\n",
    "print(df['Gender'].unique())"
   ],
   "id": "27540580f63e8036",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(df.shape)",
   "id": "40c5a5dc01ba0732",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#complete missing age with mean\n",
    "df['Age'].fillna(df['Age'].median(), inplace = True)\n",
    "# Fill with media() values  120\n",
    "s = pd.Series(df['Age'])\n",
    "s[s<18] = df['Age'].median()\n",
    "df['Age'] = s\n",
    "s = pd.Series(df['Age'])\n",
    "s[s>120] = df['Age'].median()\n",
    "df['Age'] = s\n",
    "#Ranges of Age\n",
    "df['age_range'] = pd.cut(df['Age'], [0,20,30,65,100], labels=[\"0-20\", \"21-30\", \"31-65\", \"66-100\"], include_lowest=True)\n",
    "#There are only 0.014% of self employed so let's change NaN to NOT self_employed\n",
    "#Replace \"NaN\" string from defaultString\n",
    "df['self_employed'] = df['self_employed'].replace([defaultString], 'No')\n",
    "print(df['self_employed'].unique())"
   ],
   "id": "a9c6e1580ad5b90c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#There are only 0.20% of self work_interfere so let's change NaN to \"Don't know\n",
    "#Replace \"NaN\" string from defaultString\n",
    "df['work_interfere'] = df['work_interfere'].replace([defaultString], 'Dont know')\n",
    "print(df['work_interfere'].unique())"
   ],
   "id": "b413b689961bfdc4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "labelDict = {}\n",
    "for feature in df:\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit(df[feature])\n",
    "    le_name_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "    df[feature] = le.transform(df[feature])\n",
    "    labelKey = 'label_'+feature\n",
    "    labelValue = [*le_name_mapping]\n",
    "    labelDict[labelKey]= labelValue\n",
    "for key, value in labelDict.items():\n",
    "    print(key, value)\n",
    "\n",
    "df = df.drop(['Country'], axis=1)\n",
    "df.head()"
   ],
   "id": "b5f852cbe921f694",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "total = df.isnull().sum().sort_values(ascending=False)\n",
    "percent = (df.isnull().sum()/df.isnull().count()).sort_values(ascending=False)\n",
    "missing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
    "missing_data.head(20)\n",
    "print(missing_data)"
   ],
   "id": "d7fa586d3199da43",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#correlation matrix\n",
    "corrmat = df.corr()\n",
    "f, ax = plt.subplots(figsize=(12, 9))\n",
    "sns.heatmap(corrmat, vmax=.8, square=True);\n",
    "plt.show()"
   ],
   "id": "ad81a85eb350c62e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "k = 10 \n",
    "cols = corrmat.nlargest(k, 'treatment')['treatment'].index\n",
    "cm = np.corrcoef(df[cols].values.T)\n",
    "sns.set(font_scale=1.25)\n",
    "hm = sns.heatmap(cm, cbar=True, annot=True, square=True, fmt='.2f', annot_kws={'size': 10}, yticklabels=cols.values, xticklabels=cols.values)\n",
    "plt.show()"
   ],
   "id": "1768b167efc7c8a6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "sns.histplot(df[\"Age\"], bins=24)\n",
    "plt.title(\"Distribution and density by Age\")\n",
    "plt.xlabel(\"Age\")"
   ],
   "id": "111166feb8a7419e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Mostly the people within age 10 to 20 are mentally disturbed",
   "id": "744ad8954acfd4f7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "j = sns.FacetGrid(df, col='treatment')\n",
    "j = j.map(sns.histplot, \"Age\")"
   ],
   "id": "acf59103d0cb2846",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "labels = labelDict['label_Gender']\n",
    "j = sns.countplot(x=\"treatment\", data=df)\n",
    "j.set_xticks(range(len(labels)))\n",
    "j.set_xticklabels(labels)\n",
    "plt.title('Total Distribution by treated or not')"
   ],
   "id": "8fd43305ecf42681",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "raw",
   "source": "Inference: More male are treated than woman",
   "id": "fb38caa18f731715"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "o = labelDict['label_age_range']\n",
    "j = sns.catplot(x=\"age_range\", y=\"treatment\", hue=\"Gender\", data=df, kind=\"bar\",  errorbar=None, aspect=2, legend_out = True)\n",
    "j.set_xticklabels(o)\n",
    "plt.title('Probability of mental health condition')\n",
    "plt.ylabel('Probability x 100')\n",
    "plt.xlabel('Age')\n",
    "new_labels = labelDict['label_Gender']\n",
    "for t, l in zip(j._legend.texts, new_labels): t.set_text(l)\n",
    "j.fig.subplots_adjust(top=0.9,right=0.8)\n",
    "plt.show()"
   ],
   "id": "ec08313b0436897c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "o = labelDict['label_family_history']\n",
    "j = sns.catplot(x=\"family_history\", y=\"treatment\", hue=\"Gender\", data=df, kind=\"bar\", errorbar=None, aspect=2, legend_out = True)\n",
    "j.set_xticklabels(o)\n",
    "plt.title('Probability of mental health condition')\n",
    "plt.ylabel('Probability x 100')\n",
    "plt.xlabel('Family History')\n",
    "new_labels = labelDict['label_Gender']\n",
    "for t, l in zip(j._legend.texts, new_labels): t.set_text(l)\n",
    "j.fig.subplots_adjust(top=0.9,right=0.8)\n",
    "plt.show()"
   ],
   "id": "7a453bfa588351ad",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "raw",
   "source": [
    "Inference:Those who are having a family history of mental health problems, the Probability of mental\n",
    "health will be high. So here we can see that probability of mental health conditions for transgender is almost 90% as they\n",
    "have a family history of medical health conditions."
   ],
   "id": "d862fbe0eba84f88"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "o = labelDict['label_care_options']\n",
    "j = sns.catplot(x=\"care_options\", y=\"treatment\", hue=\"Gender\", data=df, kind=\"bar\", errorbar=None, aspect=2, legend_out = True)\n",
    "j.set_xticklabels(o)\n",
    "plt.title('Probability of mental health condition')\n",
    "plt.ylabel('Probability x 100')\n",
    "plt.xlabel('Care options')\n",
    "new_labels = labelDict['label_Gender']\n",
    "for t, l in zip(j._legend.texts, new_labels): t.set_text(l)\n",
    "j.fig.subplots_adjust(top=0.9,right=0.8)\n",
    "plt.show()"
   ],
   "id": "a64d90821de009c3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "raw",
   "source": [
    "Inference: Those who are not having care options, the Probability of mental health situation will be high. So here we can see\n",
    "that the mental health of transgender is very high who have not care options and low for those who are having care options."
   ],
   "id": "97500f742ea21209"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "o = labelDict['label_benefits']\n",
    "j = sns.catplot(x=\"care_options\", y=\"treatment\", hue=\"Gender\", data=df, kind=\"bar\", errorbar=None, aspect=2, legend_out = True)\n",
    "j.set_xticklabels(o)\n",
    "plt.title('Probability of mental health condition')\n",
    "plt.ylabel('Probability x 100')\n",
    "plt.xlabel('Benefits')\n",
    "new_labels = labelDict['label_Gender']\n",
    "for t, l in zip(j._legend.texts, new_labels): t.set_text(l)\n",
    "j.fig.subplots_adjust(top=0.9,right=0.8)\n",
    "plt.show()"
   ],
   "id": "d8fcedc7dda6bf78",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "raw",
   "source": [
    "Those who are not having any benefits, the Probability of mental health conditions will be high. So here we can see that\n",
    "probability of mental health conditions for transgender is very high who have not getting any benefits. and probability is low \n",
    "for those who are having benefits options."
   ],
   "id": "f118e1b4cdc4140f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "o = labelDict['label_work_interfere']\n",
    "j = sns.catplot(x=\"work_interfere\", y=\"treatment\", hue=\"Gender\", data=df, kind=\"bar\", errorbar=None, aspect=2, legend_out = True)\n",
    "j.set_xticklabels(o)\n",
    "plt.title('Probability of mental health condition')\n",
    "plt.ylabel('Probability x 100')\n",
    "plt.xlabel('Work interfere')\n",
    "new_labels = labelDict['label_Gender']\n",
    "for t, l in zip(j._legend.texts, new_labels): t.set_text(l)\n",
    "j.fig.subplots_adjust(top=0.9,right=0.8)\n",
    "plt.show()"
   ],
   "id": "9aaf7ca607532641",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "raw",
   "source": [
    "Those who are not having any work interference, the Probability of mental health conditions will be very less. and probability \n",
    "is high for those who are having work interference rarely."
   ],
   "id": "3ac8aa86acff21df"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#Scaling to normalize\n",
    "scaler = MinMaxScaler()\n",
    "df['Age'] = scaler.fit_transform(df[['Age']])\n",
    "df.head()"
   ],
   "id": "3e3d4849cbb193b2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#Finding correlation of other set of data with treatment\n",
    "corre = df.corr()['treatment']\n",
    "print(corre)"
   ],
   "id": "6b339c8069fca332",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "feature_cols = ['Age', 'family_history', 'benefits', 'care_options', 'anonymity', 'obs_consequence']\n",
    "x = df[feature_cols]\n",
    "y = df.treatment\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(x, y, test_size=0.30, random_state=0)\n",
    "forest = ExtraTreesClassifier(n_estimators=250,\n",
    "                              random_state=0)\n",
    "forest.fit(x, y)\n",
    "importances = forest.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in forest.estimators_],\n",
    "             axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "labels = []\n",
    "for f in range(x.shape[1]):\n",
    "    labels.append(feature_cols[f])\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(x.shape[1]), importances[indices],\n",
    "       color=\"r\", yerr=std[indices], align=\"center\")\n",
    "plt.xticks(range(x.shape[1]), labels, rotation='vertical')\n",
    "plt.xlim([-1, x.shape[1]])\n",
    "plt.show()"
   ],
   "id": "b017ed7b79d8d7e4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def evalModel(model, y_test1, y_pred_class, plot=True):\n",
    "    print('Accuracy:', metrics.accuracy_score(y_test1, y_pred_class))\n",
    "    print('Null accuracy:n', y_test1.value_counts())\n",
    "    print('Percentage of ones:', y_test1.mean())\n",
    "    print('Percentage of zeros:',1 - y_test1.mean())\n",
    "    print('True:', y_test1.values[0:25])\n",
    "    print('Pred:', y_pred_class[0:25])\n",
    "    #Confusion matrix\n",
    "    confusion = metrics.confusion_matrix(y_test1, y_pred_class)\n",
    "    #[row, column]\n",
    "    TP = confusion[1, 1]\n",
    "    TN = confusion[0, 0]\n",
    "    FP = confusion[0, 1]\n",
    "    FN = confusion[1, 0]\n",
    "    # visualize Confusion Matrix\n",
    "    sns.heatmap(confusion,annot=True,fmt=\"d\")\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.show()\n",
    "    accuracy = metrics.accuracy_score(y_test1, y_pred_class)\n",
    "    print('Classification Accuracy:', accuracy)\n",
    "    print('Classification Error:', 1 - metrics.accuracy_score(y_test1, y_pred_class))\n",
    "    fp_rate = FP / float(TN + FP)\n",
    "    print('False Positive Rate:', fp_rate)\n",
    "    print('Precision:', metrics.precision_score(y_test1, y_pred_class))\n",
    "    print('First 10 predicted responses:n', model.predict(X_test1)[0:10])\n",
    "    print('First 10 predicted probabilities of class members:n', model.predict_proba(X_test1)[0:10])\n",
    "    model.predict_proba(X_test1)[0:10, 1]\n",
    "    y_pred_prob = model.predict_proba(X_test1)[:, 1]\n",
    "    if plot == True:\n",
    "        # histogram of predicted probabilities\n",
    "        plt.rcParams['font.size'] = 12\n",
    "        plt.hist(y_pred_prob, bins=8)\n",
    "      \n",
    "        plt.xlim(0,1)\n",
    "        plt.title('Histogram of predicted probabilities')\n",
    "        plt.xlabel('Predicted probability of treatment')\n",
    "        plt.ylabel('Frequency')\n",
    "    y_pred_prob = y_pred_prob.reshape(-1,1)\n",
    "    y_pred_class = binarize(y_pred_prob, threshold=0.5)\n",
    "    print('First 10 predicted probabilities:n', y_pred_prob[0:10])\n",
    "    roc_auc = metrics.roc_auc_score(y_test1, y_pred_prob)\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_test1, y_pred_prob)\n",
    "    if plot == True:\n",
    "        plt.figure()\n",
    "        plt.plot(fpr, tpr, color='darkorange', label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "        plt.plot([0, 1], [0, 1], color='navy', linestyle='--')\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.0])\n",
    "        plt.rcParams['font.size'] = 12\n",
    "        plt.title('ROC curve for treatment classifier')\n",
    "        plt.xlabel('False Positive Rate (1 - Specificity)')\n",
    "        plt.ylabel('True Positive Rate (Sensitivity)')\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.show()\n",
    "    \"\"\"def evaluate_threshold(threshold):\n",
    "        print('Specificity for ' + str(threshold) + ' :', 1 - fpr[thresholds > threshold][-1])\n",
    "        predict_mine = np.where(y_pred_prob > 0.50, 1, 0)\n",
    "        confusion = metrics.confusion_matrix(y_test1, predict_mine)\n",
    "        print(confusion)\"\"\"\n",
    "    return accuracy"
   ],
   "id": "e58ede83bc7d4a4f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def tuningGridSearch(knn):\n",
    "    k_range = range(1,31)\n",
    "    param_grid = {'n_neighbors': k_range}\n",
    "    print(param_grid)\n",
    "    grid = GridSearchCV(knn, param_grid, cv=10, scoring='accuracy')\n",
    "    grid.fit(x, y)\n",
    "    print(grid.best_params_)\n",
    "    print('GridSearch best score', grid.best_score_)\n",
    "    print('GridSearch best params', grid.best_params_)\n",
    "    print('GridSearch best estimator', grid.best_estimator_)\n",
    "    "
   ],
   "id": "bd7e5b7cc6ec4cac",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def logisticRegression():\n",
    "    logreg = LogisticRegression()\n",
    "    logreg.fit(X_train1, y_train1)\n",
    "    y_pred_class = logreg.predict(X_test1)\n",
    "    accuracy_score = evalModel(logreg, y_test1, y_pred_class)\n",
    "    print(accuracy_score)"
   ],
   "id": "33a9687a01907a4f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "logisticRegression()",
   "id": "6df94c0e7f57db4d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def Knn():\n",
    "    # Calculating the best parameters\n",
    "    knn = KNeighborsClassifier(n_neighbors=5)\n",
    "   \n",
    "    k_range = range(1, 31)\n",
    "    weight_options = ['uniform', 'distance']\n",
    "    \n",
    "    param_dist = dict(N_neighbors=k_range, weights=weight_options)\n",
    "    tuningGridSearch(knn)\n",
    "   \n",
    "    knn = KNeighborsClassifier(n_neighbors=27, weights='uniform')\n",
    "    knn.fit(X_train1, y_train1)\n",
    "   \n",
    "    y_pred_class = knn.predict(X_test1)\n",
    "    accuracy_score = evalModel(knn, y_test1, y_pred_class, True)\n",
    "    print(accuracy_score)\n",
    "Knn()"
   ],
   "id": "5cb12823f9cdf733",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "import argparse"
   ],
   "id": "cacc3a1fff2cc774",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "batch_size = 100\n",
    "train_steps = 1000\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.30, random_state=0)\n",
    "def train_input_fn(features, labels, batch_size):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\n",
    "    return dataset.shuffle(1000).repeat().batch(batch_size)\n",
    "def eval_input_fn(features, labels, batch_size):\n",
    "    features=dict(features)\n",
    "    if labels is None:\n",
    "        # No labels, use only features.\n",
    "        inputs = features\n",
    "    else:\n",
    "        inputs = (features, labels)\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(inputs)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    # Return the dataset.\n",
    "    return dataset"
   ],
   "id": "b33b9663ac167228",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "age = tf.feature_column.numeric_column(\"Age\")\n",
    "obs = tf.feature_column.numeric_column(\"obs_consequence\")\n",
    "family_history = tf.feature_column.numeric_column(\"family_history\")\n",
    "benefits = tf.feature_column.numeric_column(\"benefits\")\n",
    "care_options = tf.feature_column.numeric_column(\"care_options\")\n",
    "anonymity = tf.feature_column.numeric_column(\"anonymity\")\n",
    "\"\"\"leave = tf.feature_column.numeric_column(\"leave\")\n",
    "work_interfere = tf.feature_column.numeric_column(\"work_interfere\")\"\"\"\n",
    "feature_column = [age, obs, family_history, benefits, care_options, anonymity]"
   ],
   "id": "fcca65cb20e341b2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model = tf.estimator.DNNClassifier(feature_columns=feature_column, hidden_units=[20, 20], optimizer=lambda: tf.keras.optimizers.Adam(\n",
    "          learning_rate=tf.compat.v1.train.exponential_decay(\n",
    "              learning_rate=0.01,\n",
    "              global_step=tf.compat.v1.train.get_global_step(),\n",
    "              decay_steps=10000,\n",
    "              decay_rate=0.96)), activation_fn=tf.nn.relu)"
   ],
   "id": "bd5d3356aea630d5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "model.train(input_fn=lambda:train_input_fn(X_train, y_train, batch_size), steps=train_steps)",
   "id": "4af3bc02483942db",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Evaluate the model.\n",
    "eval_result = model.evaluate(\n",
    "    input_fn=lambda:eval_input_fn(X_test, y_test, batch_size))\n",
    "print('nTest set accuracy: {accuracy:0.2f}n'.format(**eval_result))\n",
    "#Data for final graph\n",
    "accuracy = eval_result['accuracy'] * 100\n",
    "print(accuracy)"
   ],
   "id": "f9d218c55e1a5c70",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout\n",
    "\n",
    "# Define the input shape. For simplicity, assume 10 time steps and 5 features.\n",
    "# The number of time steps and features should match your data.\n",
    "input_shape = (len(feature_cols))\n",
    "# Create a Sequential model\n",
    "model = Sequential([\n",
    "    Input(shape=input_shape),\n",
    "    Dense(200),\n",
    "    Dense(100),\n",
    "    Dropout(0.5),\n",
    "    Dense(50),\n",
    "    Dense(32),\n",
    "    Dense(16),\n",
    "    Dense(16),\n",
    "    Dense(8, activation=tf.nn.relu),\n",
    "    Dense(4, activation=tf.nn.relu),\n",
    "    Dense(2, activation=tf.nn.relu)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print model summary\n",
    "model.summary()\n",
    "model.fit(X_train, y_train)\n",
    "eval_result = model.evaluate(X_test, y_test)\n",
    "#Data for final graph\n",
    "accuracy = eval_result[1] * 100\n",
    "print(accuracy)"
   ],
   "id": "b1780729aae43891",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "4762d6f6c7275a74",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
